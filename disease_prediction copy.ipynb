{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "df_train = pd.read_excel(r'C:\\Users\\jites\\Desktop\\Project_folder\\Jupyter_practice\\diesease_train.xlsx')\n",
    "df_test = pd.read_excel(r'C:\\Users\\jites\\Desktop\\Project_folder\\Jupyter_practice\\diesease_test.xlsx')\n",
    "\n",
    "# df_train = df_train[:100]\n",
    "# df_train = pd.concat([df_train.iloc[500:1500], df_train.iloc[2000:3000]])\n",
    "# df_test = pd.concat([df_test.iloc[0:150], df_test.iloc[300:350]])\n",
    "# df_test = df_test[100:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4813, 2)\n",
      "(1193, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44}\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44}\n"
     ]
    }
   ],
   "source": [
    "        ## check disease type of training data and test data are same or not\n",
    "all_vals_train = [k for k,v in df_train['label'].value_counts().items()]\n",
    "print(set(all_vals_train))\n",
    "\n",
    "all_vals_test = [k for k,v in df_test['label'].value_counts().items()]\n",
    "print(set(all_vals_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been having migraines and headaches. I ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have asthma and I get wheezing and breathing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cough,high_fever,breathlessness,family_history...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chills,vomiting,high_fever,sweating,headache,n...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been having back pain, a cough, and numbn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>itching,skin_rash,dischromic__patches</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>acidity,headache,blurred_and_distorted_vision,...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>vomiting,breathlessness,sweating,chest_pain</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>vomiting,indigestion,loss_of_appetite,abdomina...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>yellowish_skin,abdominal_pain,swelling_of_stom...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4813 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     I have been having migraines and headaches. I ...      6\n",
       "1     I have asthma and I get wheezing and breathing...      1\n",
       "2     cough,high_fever,breathlessness,family_history...     12\n",
       "3     chills,vomiting,high_fever,sweating,headache,n...     15\n",
       "4     I've been having back pain, a cough, and numbn...      0\n",
       "...                                                 ...    ...\n",
       "4808              itching,skin_rash,dischromic__patches     13\n",
       "4809  acidity,headache,blurred_and_distorted_vision,...     14\n",
       "4810        vomiting,breathlessness,sweating,chest_pain     40\n",
       "4811  vomiting,indigestion,loss_of_appetite,abdomina...     37\n",
       "4812  yellowish_skin,abdominal_pain,swelling_of_stom...     35\n",
       "\n",
       "[4813 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['text']\n",
    "y_train = df_train['label']\n",
    "x_test = df_test['text']\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = torch.tensor(label_encoder.fit_transform(y_train))\n",
    "y_test_encoded = torch.tensor(label_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jites\\anaconda3\\envs\\torchenv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertForSequenceClassification, Trainer, TrainingArguments, T5Tokenizer, T5ForConditionalGeneration \n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, GPT2Config, AdamW, DataCollatorForLanguageModeling, DataCollatorForSeq2Seq, DataCollatorWithPadding\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./gpt2-custom-classification-tokenizer')\n",
    "# tokenizer = LlamaTokenizer.from_pretrained('llama-7b')\n",
    "\n",
    "\n",
    "# config = GPT2Config.from_pretrained('gpt2')\n",
    "# config.pad_token_id = tokenizer.pad_token_id\n",
    "# model = GPT2ForSequenceClassification.from_pretrained('gpt2', config=config, num_labels=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Load the pre-trained GPT-2 model and update configuration for classification\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "config.num_labels = len(label_encoder.classes_)  # Update num_labels based on your dataset\n",
    "\n",
    "# model = GPT2ForSequenceClassification.from_pretrained('gpt2', config=config).to(device)\n",
    "model = GPT2ForSequenceClassification.from_pretrained('./gpt2--custom-classification-model', config=config).to(device)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "# model = GPT2ForSequenceClassification(configuration).from_pretrained('gpt-2).to(device)\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_)).to(device)\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "# model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=len(label_encoder.classes_)).to(device)\n",
    "# model = LlamaForSequenceClassification.from_pretrained('llama-7b', num_labels=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.config.attn_pdrop = 0.2\n",
    "model.config.embd_pdrop = 0.2\n",
    "model.config.resid_pdrop = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_encodings = tokenize(x_train.tolist())\n",
    "test_encodings = tokenize(x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         # Use clone().detach() to convert data to tensors\n",
    "#         item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n",
    "#         item['labels'] = self.labels[idx].clone().detach()  # Use 'labels' key for consistency\n",
    "#         return item\n",
    "\n",
    "#         ## warning\n",
    "#     # def __getitem__(self, idx):\n",
    "#     #     item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#     #     item['label'] = self.labels[idx]\n",
    "#     #     return item\n",
    "\n",
    "#         ## this is for custome padding\n",
    "#     # def __getitem__(self, idx):\n",
    "#     #     item = {key: val[idx].tolist() for key, val in self.encodings.items()}  # Convert tensors to lists\n",
    "#     #     item['labels'] = self.labels[idx].tolist()  # Convert tensor to list\n",
    "#     #     return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "### Dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for key, val in self.encodings.items():\n",
    "            if isinstance(val, torch.Tensor):\n",
    "                item[key] = val[idx].clone().detach()\n",
    "            else:\n",
    "                item[key] = torch.tensor(val[idx])\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, y_train_encoded)\n",
    "test_dataset = CustomDataset(test_encodings, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# def pad_batch(batch):\n",
    "#     max_length = max(len(x) for x in batch['input_ids'])\n",
    "#     padded_batch = {\n",
    "#         'input_ids': [x + [tokenizer.pad_token_id] * (max_length - len(x)) for x in batch['input_ids']],\n",
    "#         'attention_mask': [([1] * len(x) + [0] * (max_length - len(x))) for x in batch['input_ids']]\n",
    "#     }\n",
    "#     return padded_batch\n",
    "\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     # Extract input_ids and attention_masks\n",
    "#     input_ids = [item['input_ids'] for item in batch]\n",
    "#     attention_masks = [item['attention_mask'] for item in batch]\n",
    "    \n",
    "#     # Apply padding\n",
    "#     padded_batch = pad_batch({'input_ids': input_ids, 'attention_mask': attention_masks})\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     input_ids_tensor = torch.tensor(padded_batch['input_ids'])\n",
    "#     attention_mask_tensor = torch.tensor(padded_batch['attention_mask'])\n",
    "#     labels_tensor = torch.tensor([item['labels'] for item in batch])\n",
    "\n",
    "#     return {'input_ids': input_ids_tensor, 'attention_mask': attention_mask_tensor, 'labels': labels_tensor}\n",
    "\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, collate_fn=collate_fn)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=8, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize model and optimizer\n",
    "# model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=len(label_encoder.classes_))\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# # Training loop\n",
    "# model.train()\n",
    "# for batch in tqdm(train_loader):\n",
    "#     input_ids = batch['input_ids']\n",
    "#     attention_mask = batch['attention_mask']\n",
    "#     labels = batch['labels']\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#     loss = outputs.loss\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Evaluation loop\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_loader):\n",
    "#         input_ids = batch['input_ids']\n",
    "#         attention_mask = batch['attention_mask']\n",
    "#         labels = batch['labels']\n",
    "        \n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         # Compute metrics as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)       ## weight_decay =>  L2 regularization\n",
    "scheduler = ReduceLROnPlateau(optimizer, min_lr=7e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9219c1a4b04e5dad4569279e169f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jites\\anaconda3\\envs\\torchenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4856, 'grad_norm': 7.932785987854004, 'learning_rate': 5e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75ecb26c6374d9a8a9d774cfe969c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17114411294460297, 'eval_runtime': 327.4133, 'eval_samples_per_second': 3.644, 'eval_steps_per_second': 0.458, 'epoch': 1.0}\n",
      "{'loss': 0.1875, 'grad_norm': 5.5900115966796875, 'learning_rate': 5e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1027, 'grad_norm': 2.436828136444092, 'learning_rate': 5e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7699fcfe4af4adc8a934eca5f64ccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07346154749393463, 'eval_runtime': 363.2819, 'eval_samples_per_second': 3.284, 'eval_steps_per_second': 0.413, 'epoch': 2.0}\n",
      "{'loss': 0.0419, 'grad_norm': 0.0461387075483799, 'learning_rate': 5e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e436d3aa7aec4c3fa130c18ca4641893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07262278348207474, 'eval_runtime': 356.4083, 'eval_samples_per_second': 3.347, 'eval_steps_per_second': 0.421, 'epoch': 2.99}\n",
      "{'train_runtime': 22349.0042, 'train_samples_per_second': 0.646, 'train_steps_per_second': 0.02, 'train_loss': 0.18858757654825847, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.18858757654825847, metrics={'train_runtime': 22349.0042, 'train_samples_per_second': 0.646, 'train_steps_per_second': 0.02, 'total_flos': 3762565695406080.0, 'train_loss': 0.18858757654825847, 'epoch': 2.990033222591362})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer, mlm=False\n",
    "# )\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,      ## 2\n",
    "    gradient_accumulation_steps=4,  # Accumulate over 4 batches to simulate a batch size of 32\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_steps=400,\n",
    "    save_steps=500,\n",
    "    warmup_steps=500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # eval_strategy=\"steps\",\n",
    "    # save_strategy='steps',\n",
    "    weight_decay=0.01,  ## L2 regularization\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,  # Load best model at the end based on evaluation\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = trainer.evaluate()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-custom-classification-tokenizer-3\\\\tokenizer_config.json',\n",
       " './gpt2-custom-classification-tokenizer-3\\\\special_tokens_map.json',\n",
       " './gpt2-custom-classification-tokenizer-3\\\\vocab.json',\n",
       " './gpt2-custom-classification-tokenizer-3\\\\merges.txt',\n",
       " './gpt2-custom-classification-tokenizer-3\\\\added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./gpt2--custom-classification-model-3')\n",
    "tokenizer.save_pretrained('./gpt2-custom-classification-tokenizer-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Symptoms => \n",
      "swelling in the right inguinal region associated with dragging pain x 2 years. Known hypertensive and on irregular treatment. Ho nocturnal frequency and on treatment. Problems vomiting,yellowish_skin,abdominal_pain,swelling_of_stomach,distention_of_abdomen,history_of_alcohol_consumption,fluid_overload\n",
      "\n",
      "Output disease=>  Alcoholic Hepatitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jites\\anaconda3\\envs\\torchenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n",
    "import json\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "label_encoder = LabelEncoder()\n",
    "# def predict(texts):\n",
    "#     encodings = tokenize(texts)\n",
    "#     outputs = model(**encodings).to(device)\n",
    "#     predictions = torch.argmax(outputs.logits, dim=1)\n",
    "#     return label_encoder.inverse_transform(predictions.tolist())\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./gpt2-custom-classification-tokenizer-3')\n",
    "model = GPT2ForSequenceClassification.from_pretrained('./gpt2--custom-classification-model-3').to(device)       ##, config=config\n",
    "\n",
    "# def tokenize(texts):\n",
    "#     return tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "def predict(texts):\n",
    "    # Tokenize and move input tensors to the correct device\n",
    "    # encodings = tokenize(texts)\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    \n",
    "    # Ensure the model is on the correct device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Move outputs to CPU for processing\n",
    "    logits = outputs.logits.cpu()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "    top_values, top_indices = torch.topk(logits, k=3)\n",
    "\n",
    "    js_data = open(r'C:\\Users\\jites\\Desktop\\Project_folder\\Jupyter_practice\\diesease_data_reverse.json')\n",
    "    json_data = json.load(js_data)\n",
    "\n",
    "    predictions = json_data.get(str(int(predictions[-1])), 'Unknown disease')\n",
    "\n",
    "    return predictions\n",
    "    # return label_encoder.inverse_transform(predictions.tolist())\n",
    "    #### return top_values, top_indices, logits\n",
    "\n",
    "\n",
    "# Example prediction\n",
    "# new_texts = [\"fatigue, mood_swings, weight_loss, restlessness, sweating,diarrhoea, excessive_hunger, muscle_weakness, irritability, abnormal_menstruation\"]\n",
    "# new_texts = [\" malaise, phlegm, throat_irritation, redness_of_eyes, sinus_pressure, runny_nose, congestion, chest_pain, loss_of_smell, muscle_pain\"]\n",
    "# new_texts = [\"I have noticed cramps in my calves are becoming more frequent and intense. It is causing me a lot of discomforts. I am also overweight and my legs have started to swell. I am worried that I may have varicose veins.\"]\n",
    "# new_texts = [\"I have been feeling really sick lately. I have been itching all over, and I have been vomiting. I have also lost a lot of weight, and I have a fever. My skin has turned yellow, and my urine is dark. I have also been having abdominal pain.\"]\n",
    "# new_texts = [\"skin_rash, high_fever, blister, red_sore_around_nose, yellow_crust_ooze\"]\n",
    "new_texts = [\"swelling in the right inguinal region associated with dragging pain x 2 years. Known hypertensive and on irregular treatment. Ho nocturnal frequency and on treatment. Problems vomiting,yellowish_skin,abdominal_pain,swelling_of_stomach,distention_of_abdomen,history_of_alcohol_consumption,fluid_overload\"]\n",
    "predictions = predict(new_texts)\n",
    "\n",
    "\n",
    "print(\"Input Symptoms => \")\n",
    "print(new_texts[0])\n",
    "# print(\"I have been feeling really sick lately. I have been itching all over, and I have been vomiting. I have also lost a lot of weight, and I have a fever.\")\n",
    "# print(\"My skin has turned yellow, and my urine is dark. I have also been having abdominal pain.\")\n",
    "print()\n",
    "print(\"Output disease=> \", predictions)\n",
    "\n",
    "\n",
    "\n",
    "# def get_probabilities(logits):\n",
    "#     return softmax(logits, dim=-1)\n",
    "\n",
    "# def calculate_top_k_accuracy(predictions, labels):\n",
    "#     top_values, top_indices = get_top_k_predictions(predictions, k=k)\n",
    "#     probabilities = get_probabilities(predictions)\n",
    "    \n",
    "\n",
    "#     js_data = open(r'C:\\Users\\jites\\Desktop\\Project_folder\\Jupyter_practice\\diesease_data_reverse.json')\n",
    "#     json_data = json.load(js_data)\n",
    "\n",
    "\n",
    "#     correct = 0\n",
    "#     for i in range(len(labels)):\n",
    "#         true_label = labels[i].item()\n",
    "#         top_k_indices = top_indices[i].tolist()\n",
    "#         top_k_probabilities = probabilities[i][top_k_indices].tolist()\n",
    "        \n",
    "#         if true_label in top_k_indices:\n",
    "#             correct += 1\n",
    "    \n",
    "#     accuracy = correct / len(labels)\n",
    "#     return top_values, top_indices, probabilities, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16, you can accelerate training with the argument --bf16\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "major, _ = torch.cuda.get_device_capability()\n",
    "if major >= 8:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Your GPU supports bfloat16, you can accelerate training with the argument --bf16\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
