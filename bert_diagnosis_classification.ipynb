{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Lab Test Results</th>\n",
       "      <th>Illness History</th>\n",
       "      <th>Diagnosis Suggested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hot Flashes, Muscle Cramps</td>\n",
       "      <td>HR: 97 bpm, BP: 103/78 mmHg, RR: 13, O2 Sat: 9...</td>\n",
       "      <td>Leg Weakness, Strong Urine Odor</td>\n",
       "      <td>Chronic Obstructive Pulmonary Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bleeding after Injury, Hoarse Voice, Dehydration</td>\n",
       "      <td>HR: 75 bpm, RR: 23, Temp: 37.3°C, BP: 146/119 ...</td>\n",
       "      <td>Blue or Purple Fingers, Dehydration</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>Male</td>\n",
       "      <td>Leg Pain, Sore Throat, Dry Eyes, Swollen Ankle...</td>\n",
       "      <td>HR: 93 bpm, BP: 98/113 mmHg, Temp: 38.9°C, Amy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acute kidney injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender                                           Symptoms  \\\n",
       "0   84  Female                         Hot Flashes, Muscle Cramps   \n",
       "1   31    Male   Bleeding after Injury, Hoarse Voice, Dehydration   \n",
       "2   51    Male  Leg Pain, Sore Throat, Dry Eyes, Swollen Ankle...   \n",
       "\n",
       "                                    Lab Test Results  \\\n",
       "0  HR: 97 bpm, BP: 103/78 mmHg, RR: 13, O2 Sat: 9...   \n",
       "1  HR: 75 bpm, RR: 23, Temp: 37.3°C, BP: 146/119 ...   \n",
       "2  HR: 93 bpm, BP: 98/113 mmHg, Temp: 38.9°C, Amy...   \n",
       "\n",
       "                       Illness History                    Diagnosis Suggested  \n",
       "0      Leg Weakness, Strong Urine Odor  Chronic Obstructive Pulmonary Disease  \n",
       "1  Blue or Purple Fingers, Dehydration                                 Cancer  \n",
       "2                                  NaN                    Acute kidney injury  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r'C:\\Users\\jites\\Desktop\\new_folder\\synthetic_patient_data_with_lab_results.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "# Combine all relevant information into a single input text\n",
    "df['input_text'] = df.apply(lambda x: f\"Age: {x['Age']} Gender: {x['Gender']} Symptoms: {x['Symptoms']} History: {x['Illness History']} LabTests: {x['Lab Test Results']}\", axis=1)\n",
    "df['Diagnosis'] = df['Diagnosis Suggested']  # Ensure you have the correct column for labels\n",
    "\n",
    "# Convert diagnosis to numerical codes\n",
    "labels = df['Diagnosis'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['input_text'], labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jites\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({'input_text': train_texts, 'labels': train_labels})\n",
    "val_dataset = Dataset.from_dict({'input_text': val_texts, 'labels': val_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['Diagnosis'].unique())).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:00<00:00, 1387.89 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1207.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['input_text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "# Preprocess the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,      ## 2 ...   8   4\n",
    "    gradient_accumulation_steps=4,  # Accumulate over 4 batches to simulate a batch size of 32\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_steps=200, ## 400,\n",
    "    save_steps=300, ## 500,\n",
    "    warmup_steps=300, ## 500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # eval_strategy=\"steps\",\n",
    "    # save_strategy='steps',\n",
    "    weight_decay=0.01,  ## L2 regularization\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,  # Load best model at the end based on evaluation\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=3,                    # Limit saved models\n",
    "    eval_accumulation_steps=4,             # Accumulate eval gradients\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "num_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # Example: 10% of training steps for warmup\n",
    "\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, \n",
    "                            num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/280 [00:00<?, ?it/s]c:\\Users\\jites\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "                                                \n",
      " 10%|█         | 28/280 [05:19<47:15, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.268796682357788, 'eval_runtime': 3.0126, 'eval_samples_per_second': 33.194, 'eval_steps_per_second': 4.315, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|██        | 56/280 [10:32<41:07, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2538602352142334, 'eval_runtime': 1.5886, 'eval_samples_per_second': 62.948, 'eval_steps_per_second': 8.183, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 30%|███       | 84/280 [15:55<37:10, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.241973876953125, 'eval_runtime': 1.5932, 'eval_samples_per_second': 62.765, 'eval_steps_per_second': 8.159, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 100/280 [18:21<28:13,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2851, 'grad_norm': 2.805276393890381, 'learning_rate': 0.0001785714285714286, 'epoch': 3.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|████      | 113/280 [20:23<24:57,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.251154899597168, 'eval_runtime': 1.7478, 'eval_samples_per_second': 57.214, 'eval_steps_per_second': 7.438, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|█████     | 141/280 [23:30<15:11,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.250839948654175, 'eval_runtime': 1.5778, 'eval_samples_per_second': 63.38, 'eval_steps_per_second': 8.239, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 141/280 [23:32<23:12, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1412.0879, 'train_samples_per_second': 6.374, 'train_steps_per_second': 0.198, 'train_loss': 3.285126273513686, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:01<00:00,  8.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.241973876953125,\n",
       " 'eval_runtime': 1.6026,\n",
       " 'eval_samples_per_second': 62.397,\n",
       " 'eval_steps_per_second': 8.112,\n",
       " 'epoch': 4.991150442477876}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./bert_diagnosis_model')\n",
    "tokenizer.save_pretrained('./bert_diagnosis_tokenizer')\n",
    "\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
