{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple LSTM ( one input ans one output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we create an LSTM model with one LSTM layer of 50 neurons and relu activation functions. You can see the input shape is (1,1) \n",
    "since our data has one time-step with one feature.\n",
    "\"\"\"\n",
    "\n",
    "            #### normal LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())\n",
    "\n",
    "X = [x+1 for x in range(20)]\n",
    "Y = [y * 15 for y in X]\n",
    "\n",
    "X = array(X).reshape(20, 1, 1)\n",
    "model.fit(X, Y, epochs=2000, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X, Y, epochs=2000, validation_split=0.2, verbose=1, batch_size=5)\n",
    "\n",
    "\"\"\"\n",
    "In the above model, we have two LSTM layers. Notice, the first LSTM layer has parameter return_sequences, which is set to True. \n",
    "When the return sequence is set to True, the output of the hidden state of each neuron is used as an input to the next LSTM layer.\n",
    "\"\"\"\n",
    "\n",
    "test_input = array([30])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-One Sequence Problems with Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = 25\n",
    "\n",
    "X1 = list()\n",
    "X2 = list()\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "X1 = [(x+1)*2 for x in range(25)]\n",
    "X2 = [(x+1)*3 for x in range(25)]\n",
    "Y = [x1*x2 for x1,x2 in zip(X1,X2)]\n",
    "\n",
    "print(X1)\n",
    "print(X2)\n",
    "print(Y)\n",
    "\n",
    "\"\"\"\n",
    "Each element in the output list is basically the product of the corresponding elements in the X1 and X2 lists. For instance, the second element\n",
    "in the output list is 24, which is the product of the second element in list X1 i.e. 4, and the second element in the list X2 i.e. 6.\n",
    "\n",
    "The input will consist of the combination of X1 and X2 lists, where each list will be represented as a column. The following \n",
    "script creates the final input:\n",
    "\n",
    "[2, 4, 6, ..............]\n",
    "[3, 6, 9, ..............]\n",
    "[6, 24, 54, ..............]\n",
    "\"\"\"\n",
    "\n",
    "X = np.column_stack((X1, X2))\n",
    "\n",
    "\"\"\"\n",
    "[[ 2  3]\n",
    " [ 4  6]\n",
    " [ 6  9]\n",
    " .\n",
    " .\n",
    " .]\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Here the X variable contains our final feature set. You can see it contains two columns i.e. two features per input. As we discussed earlier,\n",
    "we need to convert the input into a 3-dimensional shape. Our input has 25 samples, where each sample consists of 1 time-step and each \n",
    "time-step consists of 2 features. The following script reshapes the input.\n",
    "\"\"\"\n",
    "\n",
    "X = array(X).reshape(25, 1, 2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(80, activation='relu', input_shape=(1, 2)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "Here our LSTM layer contains 80 neurons. We have two dense layers where the first layer contains 10 neurons and the second dense layer, \n",
    "which also acts as the output layer, contains 1 neuron.\n",
    "\"\"\"\n",
    "model.fit(X, Y, epochs=2000, validation_split=0.2, batch_size=5)\n",
    "\"\"\"\n",
    "Let's test our trained model on a new data point. Our data point will have two features i.e. (55,80) the actual output should be 55 x 80 = 4400\n",
    "\"\"\"\n",
    "test_input = array([55,80])\n",
    "test_input = test_input.reshape((1, 1, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(1, 2)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "To improve the accuracy, we will reduce the batch size, and since our model is more complex now we can also reduce the number of epochs. \n",
    "\"\"\"\n",
    "history = model.fit(X, Y, epochs=1000, validation_split=0.1, verbose=1, batch_size=3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
