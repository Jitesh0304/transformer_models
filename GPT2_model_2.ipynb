{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChiefComplaint</th>\n",
       "      <th>PresentProblemLocation</th>\n",
       "      <th>PreProbDuration</th>\n",
       "      <th>PreProbOnset</th>\n",
       "      <th>PreProbSeverity</th>\n",
       "      <th>AttackType</th>\n",
       "      <th>SmokingHabitType</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>ALCHOLIC</th>\n",
       "      <th>DietryHabit</th>\n",
       "      <th>...</th>\n",
       "      <th>TreatmentType</th>\n",
       "      <th>SurgeryType</th>\n",
       "      <th>SurgeryDurationH</th>\n",
       "      <th>SurgeryDurationM</th>\n",
       "      <th>AnesthicTypeName</th>\n",
       "      <th>AnesRecoverySmoothType</th>\n",
       "      <th>RecorveryType</th>\n",
       "      <th>Followupdate</th>\n",
       "      <th>DoctorRemark</th>\n",
       "      <th>Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ho intermittent pain abdomen and flatulence X ...</td>\n",
       "      <td>Abdomen problem</td>\n",
       "      <td>Complains from 1 month ago</td>\n",
       "      <td>Gradually it happen</td>\n",
       "      <td>nan</td>\n",
       "      <td>Intermittent attack</td>\n",
       "      <td>Patient does not have smoking habit</td>\n",
       "      <td>Light Worker</td>\n",
       "      <td>Does not drink alcohol</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>Treatment type OPERATIVE</td>\n",
       "      <td>Surgery type CHOLECYSTECTOMY</td>\n",
       "      <td>nan</td>\n",
       "      <td>40 minutes</td>\n",
       "      <td>Anesthic type General</td>\n",
       "      <td>Anes smooth recovery</td>\n",
       "      <td>NORMAL recovery</td>\n",
       "      <td>Follow-up date 20 December 2014</td>\n",
       "      <td>nan</td>\n",
       "      <td>Ho intermittent pain abdomen and flatulence X ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During routine health checkup gallstone detect...</td>\n",
       "      <td>Abdomen problem</td>\n",
       "      <td>Complains from 2 months ago</td>\n",
       "      <td>nan</td>\n",
       "      <td>Mild problem</td>\n",
       "      <td>No attack</td>\n",
       "      <td>Patient does not have smoking habit</td>\n",
       "      <td>Moderate Worker</td>\n",
       "      <td>Drinks alcohol</td>\n",
       "      <td>Non Vegetarian</td>\n",
       "      <td>...</td>\n",
       "      <td>Treatment type OPERATIVE</td>\n",
       "      <td>Surgery type CHOLECYSTECTOMY</td>\n",
       "      <td>nan</td>\n",
       "      <td>30 minutes</td>\n",
       "      <td>Anesthic type General</td>\n",
       "      <td>Anes smooth recovery</td>\n",
       "      <td>NORMAL recovery</td>\n",
       "      <td>Follow-up date 20 December 2014</td>\n",
       "      <td>nan</td>\n",
       "      <td>During routine health checkup gallstone detect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ChiefComplaint PresentProblemLocation  \\\n",
       "0  Ho intermittent pain abdomen and flatulence X ...        Abdomen problem   \n",
       "1  During routine health checkup gallstone detect...        Abdomen problem   \n",
       "\n",
       "               PreProbDuration         PreProbOnset PreProbSeverity  \\\n",
       "0   Complains from 1 month ago  Gradually it happen             nan   \n",
       "1  Complains from 2 months ago                  nan    Mild problem   \n",
       "\n",
       "            AttackType                     SmokingHabitType PhysicalActivity  \\\n",
       "0  Intermittent attack  Patient does not have smoking habit     Light Worker   \n",
       "1            No attack  Patient does not have smoking habit  Moderate Worker   \n",
       "\n",
       "                 ALCHOLIC     DietryHabit  ...             TreatmentType  \\\n",
       "0  Does not drink alcohol             nan  ...  Treatment type OPERATIVE   \n",
       "1          Drinks alcohol  Non Vegetarian  ...  Treatment type OPERATIVE   \n",
       "\n",
       "                    SurgeryType SurgeryDurationH SurgeryDurationM  \\\n",
       "0  Surgery type CHOLECYSTECTOMY              nan       40 minutes   \n",
       "1  Surgery type CHOLECYSTECTOMY              nan       30 minutes   \n",
       "\n",
       "        AnesthicTypeName AnesRecoverySmoothType    RecorveryType  \\\n",
       "0  Anesthic type General   Anes smooth recovery  NORMAL recovery   \n",
       "1  Anesthic type General   Anes smooth recovery  NORMAL recovery   \n",
       "\n",
       "                      Followupdate DoctorRemark  \\\n",
       "0  Follow-up date 20 December 2014          nan   \n",
       "1  Follow-up date 20 December 2014          nan   \n",
       "\n",
       "                                           Paragraph  \n",
       "0  Ho intermittent pain abdomen and flatulence X ...  \n",
       "1  During routine health checkup gallstone detect...  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = r'C:\\Users\\jites\\Desktop\\Jupyter_practice\\FInal_data_20_columns_2.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df = df.astype(str)\n",
    "df = df.fillna(\"\")\n",
    "df = df[:2000]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and validation\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# Load pre-trained GPT-2 tokenizer and model\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "# model = GPT2LMHeadModel.from_pretrained('./gpt2-finetuned-model-two-2').to(device)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('./gpt2-finetuned-tokenizer-two-2')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Regularization: Add dropout and weight decay\n",
    "model.config.attn_pdrop = 0.2\n",
    "model.config.embd_pdrop = 0.2\n",
    "model.config.resid_pdrop = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize data\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# # Create dataset from pandas DataFrame\n",
    "# def dataset_from_dataframe(df, tokenizer):\n",
    "#     texts = df['Paragraph'].tolist()\n",
    "#     labels = [' '.join([f\"{label}: {sentence}\" for label, sentence in zip(df.columns[:-1], row[:-1])]) for row in df.itertuples(index=False)]\n",
    "#     data = {'text': [f\"{text} => {label}\" for text, label in zip(texts, labels)]}\n",
    "#     return TextDataset(\n",
    "#         tokenizer=tokenizer,\n",
    "#         file_path=None,\n",
    "#         block_size=128,\n",
    "#         overwrite_cache=True,\n",
    "#         dataset=data,\n",
    "#         cache_dir=\"./cached_dataset\"\n",
    "#     )\n",
    "# train_dataset = dataset_from_dataframe(train_df, tokenizer)\n",
    "# val_dataset = dataset_from_dataframe(val_df, tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "# # Function to create a temporary text file for TextDataset\n",
    "# def dataset_from_dataframe(df, tokenizer, tmp_file_path):\n",
    "#     texts = df['Paragraph'].tolist()\n",
    "#     labels = [' '.join([f\"{label}: {sentence}\" for label, sentence in zip(df.columns[:-1], row[:-1])]) for row in df.itertuples(index=False)]\n",
    "\n",
    "#     with open(tmp_file_path, 'w', encoding='utf-8') as f:\n",
    "#         for text, label in zip(texts, labels):\n",
    "#             f.write(f\"{text} => {label}\\n\")\n",
    "\n",
    "#     return TextDataset(\n",
    "#         tokenizer=tokenizer,\n",
    "#         file_path=tmp_file_path,\n",
    "#         block_size=128,\n",
    "#         overwrite_cache=True\n",
    "#     )\n",
    "\n",
    "\n",
    "# # File paths for temporary storage\n",
    "# train_file_path = './train_data.txt'\n",
    "# val_file_path = './val_data.txt'\n",
    "\n",
    "# train_dataset = dataset_from_dataframe(train_df, tokenizer, train_file_path)\n",
    "# val_dataset = dataset_from_dataframe(val_df, tokenizer, val_file_path)\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer, mlm=False\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d95477d5e1d4340808ade73d7f452fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d900e20984141bedde65b7144dd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(df):\n",
    "    texts = df['Paragraph'].tolist()\n",
    "    labels = [' '.join([f\"{label}: {sentence}\" for label, sentence in zip(df.columns[:-1], row[:-1])]) for row in df.itertuples(index=False)]\n",
    "    \n",
    "    # Create a list of dictionaries\n",
    "    data = [{'text': f\"{text} => {label}\"} for text, label in zip(texts, labels)]\n",
    "    return Dataset.from_list(data)\n",
    "\n",
    "# Create Hugging Face datasets from DataFrames\n",
    "train_dataset = create_dataset(train_df)\n",
    "val_dataset = create_dataset(val_df)\n",
    "\n",
    "# Tokenize datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)       ## weight_decay =>  L2 regularization\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=500, eta_min=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3421d021fd97480f9c71542976e62e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jites\\anaconda3\\envs\\torchenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d4a583c81c46f3a1d07d5cf0a698af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27029281854629517, 'eval_runtime': 69.212, 'eval_samples_per_second': 5.779, 'eval_steps_per_second': 0.722, 'epoch': 1.0}\n",
      "{'loss': 0.6584, 'grad_norm': 0.9943187236785889, 'learning_rate': 4.570288237343631e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad485c9714a34cfeb99aa76683369519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22748272120952606, 'eval_runtime': 72.3253, 'eval_samples_per_second': 5.531, 'eval_steps_per_second': 0.691, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34684cc0d634109bb01d8d44208c589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2131483405828476, 'eval_runtime': 67.3374, 'eval_samples_per_second': 5.94, 'eval_steps_per_second': 0.743, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 12734.9679, 'train_samples_per_second': 0.377, 'train_steps_per_second': 0.012, 'train_loss': 0.5115227381388346, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./gpt2-finetuned-tokenizer-two-4\\\\tokenizer_config.json',\n",
       " './gpt2-finetuned-tokenizer-two-4\\\\special_tokens_map.json',\n",
       " './gpt2-finetuned-tokenizer-two-4\\\\vocab.json',\n",
       " './gpt2-finetuned-tokenizer-two-4\\\\merges.txt',\n",
       " './gpt2-finetuned-tokenizer-two-4\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,      ## 2\n",
    "    gradient_accumulation_steps=4,  # Accumulate over 4 batches to simulate a batch size of 32\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_steps=400,\n",
    "    save_steps=500,\n",
    "    warmup_steps=500,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # eval_strategy=\"steps\",\n",
    "    # save_strategy='steps',\n",
    "    # weight_decay=0.01,  ## L2 regularization\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,  # Load best model at the end based on evaluation\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=repo_name,\n",
    "#     group_by_length=True,\n",
    "#     length_column_name='input_length',\n",
    "#     per_device_train_batch_size=24,\n",
    "#     gradient_accumulation_steps=2,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     num_train_epochs=20,\n",
    "#     fp16=True,\n",
    "#     save_steps=1000,\n",
    "#     save_strategy='steps', # we cannot set it to \"no\". Otherwise, the model cannot guess the best checkpoint.\n",
    "#     eval_steps=1000,\n",
    "#     logging_steps=1000,\n",
    "#     learning_rate=5e-5,\n",
    "#     warmup_steps=500,\n",
    "#     save_total_limit=3,\n",
    "#     load_best_model_at_end = True # this will let the model save the best checkpoint\n",
    "# )\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    # train_dataset=train_dataset,\n",
    "    # eval_dataset=val_dataset,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained('./gpt2-finetuned-model-two-4')\n",
    "tokenizer.save_pretrained('./gpt2-finetuned-tokenizer-two-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     eval_steps=400,\n",
    "#     save_steps=800,\n",
    "#     warmup_steps=500,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     logging_dir='./logs',\n",
    "# )\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     overwrite_output_dir=True,\n",
    "#     output_dir='./results',          # output directory\n",
    "#     num_train_epochs=1,             # number of epochs\n",
    "#     per_device_train_batch_size=2,  # batch size per device during training\n",
    "#     per_device_eval_batch_size=2,   # batch size for evaluation\n",
    "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "#     weight_decay=0.01,               # strength of weight decay\n",
    "#     logging_dir='./logs',            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    "#     eval_steps=200,\n",
    "#     save_steps=500,\n",
    "#     eval_strategy='epoch',     # evaluate every epoch\n",
    "#     save_strategy='epoch',           # save model every epoch\n",
    "#     load_best_model_at_end=True,     # load best model at end\n",
    "#     metric_for_best_model='eval_loss', # metric to use to compare model\n",
    "#     greater_is_better=False,         # eval_loss, so lower is better\n",
    "#     learning_rate=1.005e-06\n",
    "# )\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the model and tokenizer\n",
    "# model.save_pretrained('./gpt2-finetuned-model-two-3')\n",
    "# tokenizer.save_pretrained('./gpt2-finetuned-tokenizer-two-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho right hypochondrium discomfort since 5 6 months. Umbilical hernia detected in 20 December 2014. She is non diabetic and non hypertensive. She underwent LSCS 6 years ago. USG abdomen on 20 December 2014 revealed Umbilical hernia, benign hepatic cysts with pressure effect in RHD  fibroid. MDCT on 31 December 2014 showed hepatomegaly with asymmetrical fatty infiltration and multiple non enhancing cystic lesions in the right and caudate lobes showing regular peripheral rim without enhancing mural solid component. Suggest possibilities like biliary cyst adenomas  hepatic cysts. The largest lesion is compressing the right hepatic duct with prominence of corresponding biliary radicles. There are few prominent paraaortic and interaortocaval nodes. Gastric rugae are prominent. Visualized bowel loops show no significant wall thickening or dilatation. There is umbilical hernia. Patient again admitted on 03 January 2017 with history of right upper abdominal discomfort. No ho fever. She had past ho umbilical hernia repair and drainage of right simple liver cyst done in 2015. She is known hypertensive and on treatment. USG abdomen on 30 December 2016 revealed benign hepatic cyst  hydatid . Abdomen problem . Complains from 6 months ago . Gradually it happen . Mild problem . No attack . Patient does not have smoking habit . Light Worker . Does not drink alcohol . Both VegNon Veg . Prefer meals 2 3 times a day . Prefer oil mustrad oil . Past medical history LSCS 6 years ago . No medicine refered by other . Normal 0 MicrosoftInternetExplorer4  Style Definitions  table.MsoNormalTable mso style name Table Normal ; mso tstyle rowband size0; mso tstyle colband size0; mso style noshowyes; mso style parent; mso padding alt0in 5.4pt 0in 5.4pt; mso para margin0in; mso para margin bottom.0001pt; mso paginationwidow orphan; font size10.0pt; font family Times New Roman ; 17 January 2015  Simple hepatic cyst segment Iv V with umbilical hernia omentocele 04 January 2017  Hepatic cyst rt liver segment VVI Hypertension . Treatment type OPERATIVE . Surgery type MULTIPLE . Procedure follow LAP DRAINAGE OF CYST OF CYST  LAP. ADHESIOLYSIS, RELEASE OF OMENTOCELE  MESH REPAIR OF HERNIA . Anesthic type General . Anes smooth recovery . Recommende drug INJ. PYROLATE 1 AMP .  INJ. PROPOFOL .  17 January 2015Lap. drainage of cyst lap. adhesiolysis, release of omentocele mesh repair of hernia  Lap. adhesiolysis of porta and hepatic bed. Caudate lobe Segment V VI dissected and lifting up. Deep seated cyst aspirated out. Hernia contents released using harmonic scalpel. 12x12 cm parietex mesh applied fixed with tacjer suture. 04 January 2017  Difficult lap. exploration hydatid cyst with marsupialization cholecystectomy   Cyst is situated in the postero inferior surface lateral to porta overlying upper pole of rt kidney Segment VVI. Cyst could not be exposed as GB was hindering the exploration. Lap. Cholecystectomy was done. Identification cyst was difficult as there was overlying liver tissue. Needle aspiration of cyst revealed golden bile stained fluid. Cyst was opened sucked out the scolices germinal layer. Cavity was treated with 3 NS 10 povidene iodine. Marsupialization of cyst was done. Active bleeding from cyst wall was controlled with harmonic scalpel. Margin was sutured. Operative field was irrigated with NS. The bile communication with the cyst could not be identified. Drainage applied within Sac ports were closed. Post operative biliary drainage was collected measured through drainage tube. Tissues sent for Biopsy . NORMAL recovery . Medicines suggested INJ. AMIKACIN 750 INJ. KETONOV 2AMP INJ. PANTOCID 40 . Follow-up date 28 January 2015 . CHECK UP WITH BIOPSY REPORT AFTER 7 DAYS AVOID STRAIN . NO . \n",
      "\n",
      "\n",
      "ChiefComplaint: Ho right hypochondrium discomfort since 5 6 months. Umbilical hernia detected in 20 December 2014. She is non diabetic and non hypertensive. She underwent LSCS 6 years ago. USG abdomen on 20 December 2014 revealed Umbilical hernia, benign hepatic cysts with pressure effect in RHD  fibroid. MDCT on 31 December 2014 showed hepatomegaly with asymmetrical fatty infiltration and multiple non enhancing cystic lesions in the right and caudate lobes showing regular peripheral rim without enhancing mural solid component. Suggest possibilities like biliary cyst adenomas  hepatic cysts. The largest lesion is compressing the right hepatic duct with prominence of corresponding biliary radicles. There are few prominent paraaortic and interaortocal nodes. Gastric rugae are prominent. Visualized bowel loops show no significant wall thickening or dilatation. There is umbilical hernia. Patient again admitted on 03 January 2017 with history of right upper abdominal discomfort. No ho fever. She had past ho umbilical hernia repair and drainage of right simple liver cyst done in 2015. She is known hypertensive and on treatment. USG abdomen on 30 December 2016 revealed benign hepatic cyst  hydatid PresentProblemLocation: Abdomen problem PreProbDuration: Complains from 6 months ago PreProbOnset: Gradually it happen PreProbSeverity: Mild problem AttackType: No attack SmokingHabitType: Patient does not have smoking habit PhysicalActivity: Light Worker ALCHOLIC: Does not drink alcohol DietryHabit: Both VegNon Veg MealFrequency: Prefer meals 2 3 times a day VegCookingMedia: Prefer oil mustrad oil TreatmentType: Treatment type OPERATIVE SurgeryType: Surgery type MULTIPLE SurgeryDurationH: nan SurgeryDurationM: nan AnesthicTypeName: nan AnesRecoverySmoothType: nan RecorveryType: nan Followupdate: Follow-up date 23 January 2015 DoctorRemark: nan SurgeryDurationM: nan AnesRecorveryType: nan RecorveryType: nan Followupdate: Follow-up date 23 January 2015 DoctorRemark: nan AnesRecorveryType: nan RecorveryType: nan Followupdate: Follow-up date 23 January 2015 DoctorRemark: nan AnesRecorveryType: nan\n",
      "28.4530827999115\n",
      "{\n",
      "    \"ChiefComplaint\": \" Ho right hypochondrium discomfort since 5 6 months. Umbilical hernia detected in 20 December 2014. She is non diabetic and non hypertensive. She underwent LSCS 6 years ago. USG abdomen on 20 December 2014 revealed Umbilical hernia, benign hepatic cysts with pressure effect in RHD  fibroid. MDCT on 31 December 2014 showed hepatomegaly with asymmetrical fatty infiltration and multiple non enhancing cystic lesions in the right and caudate lobes showing regular peripheral rim without enhancing mural solid component. Suggest possibilities like biliary cyst adenomas  hepatic cysts. The largest lesion is compressing the right hepatic duct with prominence of corresponding biliary radicles. There are few prominent paraaortic and interaortocal nodes. Gastric rugae are prominent. Visualized bowel loops show no significant wall thickening or dilatation. There is umbilical hernia. Patient again admitted on 03 January 2017 with history of right upper abdominal discomfort. No ho fever. She had past ho umbilical hernia repair and drainage of right simple liver cyst done in 2015. She is known hypertensive and on treatment. USG abdomen on 30 December 2016 revealed benign hepatic cyst  hydatid\",\n",
      "    \"PresentProblemLocation\": \" Abdomen problem\",\n",
      "    \"PreProbDuration\": \" Complains from 6 months ago\",\n",
      "    \"PreProbOnset\": \" Gradually it happen\",\n",
      "    \"PreProbSeverity\": \" Mild problem\",\n",
      "    \"AttackType\": \" No attack\",\n",
      "    \"SmokingHabitType\": \" Patient does not have smoking habit\",\n",
      "    \"PhysicalActivity\": \" Light Worker\",\n",
      "    \"ALCHOLIC\": \" Does not drink alcohol\",\n",
      "    \"DietryHabit\": \" Both VegNon Veg\",\n",
      "    \"MealFrequency\": \" Prefer meals 2 3 times a day\",\n",
      "    \"VegCookingMedia\": \" Prefer oil mustrad oil\",\n",
      "    \"TreatmentType\": \" Treatment type OPERATIVE\",\n",
      "    \"SurgeryType\": \" Surgery type MULTIPLE\",\n",
      "    \"SurgeryDurationH\": \" nan\",\n",
      "    \"SurgeryDurationM\": \" nan\",\n",
      "    \"AnesthicTypeName\": \" nan\",\n",
      "    \"AnesRecoverySmoothType\": \" nan\",\n",
      "    \"RecorveryType\": \" nan\",\n",
      "    \"Followupdate\": \" Follow-up date 23 January 2015\",\n",
      "    \"DoctorRemark\": \" nan\",\n",
      "    \"AnesRecorveryType\": \" nan\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
    "import time\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('./gpt2-finetuned-model-two-4').to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('./gpt2-finetuned-tokenizer-two-4')\n",
    "# Set pad token to eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Enable mixed precision if using a compatible GPU\n",
    "model = model.half() if torch.cuda.is_available() else model\n",
    "\n",
    "# Example of a generation function using a pipeline\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "def generate_labels(sent):\n",
    "    paragraph = sent\n",
    "    input_text = f\"{paragraph} =>\"\n",
    "\n",
    "    # Encode with truncation and padding\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        return_tensors='pt',\n",
    "        max_length=512,  # Adjust based on your requirement\n",
    "        truncation=True,  # Explicit truncation\n",
    "        padding='max_length'  # Padding to the max length\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    # Generate predictions with optimized settings\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=1024,  # Adjust based on your requirement\n",
    "            num_return_sequences=1,\n",
    "            num_beams=2,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Process and return the output\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    labels = output_text.split('=>')[-1].strip()\n",
    "    return labels\n",
    "\n",
    "# Example usage\n",
    "# paragraph = \"ho intermittent pain abdomen and flatulence x 1 month . abdomen problem . complains from 1 month ago . gradually it happen . intermittent attack . patient does not have smoking habit . light worker . does not drink alcohol . past medical history non diabetic. non hypertensive. she underwent lscs in 2005 . cholelithiasis . treatment type operative . surgery type cholecystectomy . procedure follow cholecystectomy . 40 minutes . anesthic type general . anes smooth recovery . gb found to be well distended. gb was retracted and calot s area was disected. cystic duct artery clipped cut. gb disected out from the liver bed.it is extracted through the epigastric port. ports were closed. gb tissue sent for biopsy . normal recovery . follow-up date 20 december 2014 .\"\n",
    "paragraph = \"Ho right hypochondrium discomfort since 5 6 months. Umbilical hernia detected in 20 December 2014. She is non diabetic and non hypertensive. She underwent LSCS 6 years ago. USG abdomen on 20 December 2014 revealed Umbilical hernia, benign hepatic cysts with pressure effect in RHD  fibroid. MDCT on 31 December 2014 showed hepatomegaly with asymmetrical fatty infiltration and multiple non enhancing cystic lesions in the right and caudate lobes showing regular peripheral rim without enhancing mural solid component. Suggest possibilities like biliary cyst adenomas  hepatic cysts. The largest lesion is compressing the right hepatic duct with prominence of corresponding biliary radicles. There are few prominent paraaortic and interaortocaval nodes. Gastric rugae are prominent. Visualized bowel loops show no significant wall thickening or dilatation. There is umbilical hernia. Patient again admitted on 03 January 2017 with history of right upper abdominal discomfort. No ho fever. She had past ho umbilical hernia repair and drainage of right simple liver cyst done in 2015. She is known hypertensive and on treatment. USG abdomen on 30 December 2016 revealed benign hepatic cyst  hydatid . Abdomen problem . Complains from 6 months ago . Gradually it happen . Mild problem . No attack . Patient does not have smoking habit . Light Worker . Does not drink alcohol . Both VegNon Veg . Prefer meals 2 3 times a day . Prefer oil mustrad oil . Past medical history LSCS 6 years ago . No medicine refered by other . Normal 0 MicrosoftInternetExplorer4  Style Definitions  table.MsoNormalTable mso style name Table Normal ; mso tstyle rowband size0; mso tstyle colband size0; mso style noshowyes; mso style parent\"\"; mso padding alt0in 5.4pt 0in 5.4pt; mso para margin0in; mso para margin bottom.0001pt; mso paginationwidow orphan; font size10.0pt; font family Times New Roman ; 17 January 2015  Simple hepatic cyst segment Iv V with umbilical hernia omentocele 04 January 2017  Hepatic cyst rt liver segment VVI Hypertension . Treatment type OPERATIVE . Surgery type MULTIPLE . Procedure follow LAP DRAINAGE OF CYST OF CYST  LAP. ADHESIOLYSIS, RELEASE OF OMENTOCELE  MESH REPAIR OF HERNIA . Anesthic type General . Anes smooth recovery . Recommende drug INJ. PYROLATE 1 AMP .  INJ. PROPOFOL .  17 January 2015Lap. drainage of cyst lap. adhesiolysis, release of omentocele mesh repair of hernia  Lap. adhesiolysis of porta and hepatic bed. Caudate lobe Segment V VI dissected and lifting up. Deep seated cyst aspirated out. Hernia contents released using harmonic scalpel. 12x12 cm parietex mesh applied fixed with tacjer suture. 04 January 2017  Difficult lap. exploration hydatid cyst with marsupialization cholecystectomy   Cyst is situated in the postero inferior surface lateral to porta overlying upper pole of rt kidney Segment VVI. Cyst could not be exposed as GB was hindering the exploration. Lap. Cholecystectomy was done. Identification cyst was difficult as there was overlying liver tissue. Needle aspiration of cyst revealed golden bile stained fluid. Cyst was opened sucked out the scolices germinal layer. Cavity was treated with 3 NS 10 povidene iodine. Marsupialization of cyst was done. Active bleeding from cyst wall was controlled with harmonic scalpel. Margin was sutured. Operative field was irrigated with NS. The bile communication with the cyst could not be identified. Drainage applied within Sac ports were closed. Post operative biliary drainage was collected measured through drainage tube. Tissues sent for Biopsy . NORMAL recovery . Medicines suggested INJ. AMIKACIN 750 INJ. KETONOV 2AMP INJ. PANTOCID 40 . Follow-up date 28 January 2015 . CHECK UP WITH BIOPSY REPORT AFTER 7 DAYS AVOID STRAIN . NO . \"\n",
    "# paragraph = \"Severe pain abdomen 4 months ago . Abdomen problem . Suddenly it happen . Severe problem . Single attack . chronic calculus cholecystitis with chronic appendicitis . Treatment type OPERATIVE . Surgery type CHOLECYSTECTOMY + APPENDICECTOMY . Procedure follow CHOLECYSTECTOMY + APPENDICECTOMY . Anesthic type General . Anes smooth recovery . GB contracted multiple cal. CBD normal Appendix chronically inflammed . Follow-up date 29 April 2000 . \"\n",
    "# paragraph = \"Co flatulence, intermitent pain 1 year. increases in empty stomach  after taking spicy food. Patient states that around the leter helf of 2017 she used to experience severe abdominal pain whichb used to radiate . Pain was sudden on onset radiating to the back, subsided gradually  would recur almost every 15 days . Abdomen problem . No attack . Patient does not have smoking habit . Light Worker . Does not drink alcohol . Both VegNon Veg . Prefer oil mustrad oil . Past medical history Not a known case of T2DMHTNThyroid. LSCS 1 yr back . Cholelithiasis . Treatment type OPERATIVE . Surgery type CHOLECYSTECTOMY . Procedure follow CHOLECYSTECTOMY . 22 minutes . Anesthic type General . Anes smooth recovery . Lap Chole performed under GA . NORMAL recovery . NO . \"\n",
    "\n",
    "print(paragraph)\n",
    "print()\n",
    "print()\n",
    "\n",
    "result = generate_labels(paragraph)\n",
    "\n",
    "print(result)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "\n",
    "def parse_output(output):\n",
    "    lines = output.split(' ')\n",
    "    labeled_sentences = {}\n",
    "    current_label = None\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            current_label, sentence = line.split(':', 1)\n",
    "            labeled_sentences[current_label.strip()] = sentence.strip()\n",
    "        else:\n",
    "            if current_label:\n",
    "                labeled_sentences[current_label] += ' ' + line.strip()\n",
    "    return labeled_sentences\n",
    "\n",
    "# Example output parsing\n",
    "parsed_result = parse_output(result)\n",
    "\n",
    "json_data = json.dumps(parsed_result, indent=4)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"ChiefComplaint\": \" Ho pain abdomen since 6 months\",\n",
    "#     \"PresentProblemLocation\": \" Abdomen problem\",\n",
    "#     \"PreProbDuration\": \" Complains from 6 months ago\",\n",
    "#     \"PreProbOnset\": \" Gradually it happen\",\n",
    "#     \"PreProbSeverity\": \" Moderate problem\",\n",
    "#     \"AttackType\": \" No attack\",\n",
    "#     \"SmokingHabitType\": \" Patient does not have smoking habit\",\n",
    "#     \"PhysicalActivity\": \" Light Worker\",\n",
    "#     \"ALCHOLIC\": \" Does not drink alcohol\",\n",
    "#     \"DietryHabit\": \" Non Vegetarian\",\n",
    "#     \"MealFrequency\": \" Prefer meals 2 3 times a day\",\n",
    "#     \"VegCookingMedia\": \" Prefer oil mustrad oil\",\n",
    "#     \"TreatmentType\": \" Treatment type CHOLECYSTECTOMY\",\n",
    "#     \"SurgeryType\": \" Surgery type CHOLECYSTECTOMY\",\n",
    "#     \"SurgeryDurationH\": \" nan\",\n",
    "#     \"SurgeryDurationM\": \" nan\",\n",
    "#     \"AnesthicTypeName\": \" Anesthic type General\",\n",
    "#     \"AnesRecoverySmoothType\": \" Anes smooth recovery\",\n",
    "#     \"RecorveryType\": \" NORMAL recovery\",\n",
    "#     \"Followupdate\": \" Follow-up date 17 January 2015\",\n",
    "#     \"DoctorRemark\": \" CHECK UP WITH BIOPSY REPORT AFTER 7 DAYS\\nHo pain abdomen since 6 months PresentProblem\",\n",
    "#     \"AnesRecorveryType\": \" NORMAL recovery\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
